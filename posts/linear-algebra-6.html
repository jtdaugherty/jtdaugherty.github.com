<html>
  <head>
    <title>Linear Algebra, Part 6: Matrix Inverses - Derivative Works</title>
    <link rel="stylesheet" type="text/css" href="http://yui.yahooapis.com/3.2.0/build/cssreset/reset-min.css">
    <link rel="stylesheet" type="text/css" href="http://yui.yahooapis.com/3.2.0/build/cssbase/base-min.css">
    <link rel="stylesheet" type="text/css" href="http://yui.yahooapis.com/3.2.0/build/cssfonts/fonts-min.css">
    <link rel="stylesheet" type="text/css" href="/stylesheets/stylesheet.css"/>
    <link rel="alternate" type="application/rss+xml" href="http://jtdaugherty.github.io/feed.xml"/>
    <script type="text/x-mathjax-config">
MathJax.Hub.Config(
  {"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] },
   tex2jax: {
     element: null,
     preview: "none",
     skipTags: ["script","noscript","style","textarea","pre","code"],
     inlineMath: [
       ['$', '$'],
       ["\\(", "\\)"],
     ],
     displayMath: [
       ['$$', '$$'],
       ["\\[", "\\]"],
     ],
     processEscapes: true,
     ignoreClass: "tex2jax_ignore|dno"
   },
   TeX: {
     extensions: ["AMSmath.js","AMSsymbols.js","cancel.js"],
     equationNumbers: { autoNumber: "AMS" },
     noUndefined: { attributes: {
                      mathcolor: "red",
                      mathbackground: "#FFEEEE",
                      mathsize: "90%" }
                  }
   },
   messageStyle: "none"
});
</script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    
  </head>
  <body>
    <div id="page">
      <div id="header">
        <a id="listing" href="/posts/">all posts</a>
        <a href="/">Derivative Works</a>
      </div>
      <div id="prev-next-links">
      <a class="prev-link" href="/posts/linear-algebra-5.html">older &raquo;</a>
  
      <a class="next-link-subdued">&laquo; newer</a>
  
</div>

<div style="display: none;">
\(
\newcommand{\vxy}[2]{\begin{bmatrix}#1 \\ #2\end{bmatrix}}
\newcommand{\sm}[1]{\bigl[\begin{smallmatrix}#1\end{smallmatrix}\bigr]}
\newcommand{\A}[0]{\mathbf{A}}
\newcommand{\BB}[0]{\mathbf{B}}
\newcommand{\CC}[0]{\mathbf{C}}
\newcommand{\RR}[0]{\mathbf{R}}
\newcommand{\TT}[0]{\mathbf{T}}
\newcommand{\xx}[0]{\mathbf{x}}
\newcommand{\bb}[0]{\mathbf{b}}
\newcommand{\pp}[0]{\mathbf{p}}
\newcommand{\qq}[0]{\mathbf{q}}
\newcommand{\uu}[0]{\mathbf{u}}
\newcommand{\vv}[0]{\mathbf{v}}
\)
</div>
<div id="post">
<h1>Linear Algebra, Part 6: Matrix Inverses</h1>
<span class="post-created">posted November 16, 2013</span>
<blockquote>
<p>In this post we'll look more at matrix inverses and why we care about them.</p>
</blockquote>
<p>In the interlude we looked at how we can view an <span class="math">\(m\times n\)</span> matrix as a function which maps vectors in <span class="math">\(\mathbb{R}^n\)</span> to vectors in <span class="math">\(\mathbb{R}^m\)</span>. Under that interpretation we saw that bijectivity means invertibility: we can get from any vector in <span class="math">\(\mathbb{R}^m\)</span> back to the original vector in <span class="math">\(\mathbb{R}^n\)</span>.</p>
<p>Why do we care about invertibility? The first reason is that with an inverse we can easily solve an equation like <span class="math">\(\A\xx=\bb\)</span> if we have an invertible matrix <span class="math">\(\A\)</span>. We find the inverse <span class="math">\(\A^{-1}\)</span> and then just compute <span class="math">\(\A^{-1}\bb\)</span> to get <span class="math">\(\xx\)</span>.</p>
<p>The next reason we care about invertibility is that we want to know how to invert matrix composition. If we have a matrix <span class="math">\(\A\BB\CC\)</span>, we know that a matrix product <span class="math">\(\A\BB\CC\)</span> is invertible if all of its factors are also invertible: <span class="math">\((\A\BB\CC)^{-1}=\CC^{-1}(\A\BB)^{-1}=\CC^{-1}\BB^{-1}\A^{-1}\)</span>.</p>
<p>An example where this matters in practice is from computer graphics: we use matrices to perform geometric transformations such as translations and rotations. Let's start with translation in <span class="math">\(\mathbb{R}^2\)</span>: if we want to translate a point <span class="math">\(\pp\)</span> (represented by a vector) by some amount <span class="math">\(a\)</span> in the <span class="math">\(x\)</span> direction and <span class="math">\(b\)</span> in the <span class="math">\(y\)</span> direction, we can construct a <em>translation matrix</em> <span class="math">\(\TT_{a,b}\)</span> and multiply it times <span class="math">\(\pp\)</span> to get a new translated point <span class="math">\(\pp&#39;\)</span>.</p>
<p><span class="math">\[
\pp = \vxy{1}{2}
\hskip{0.5in}
\pp&#39; = \TT_{2,3}\pp = \vxy{3}{5}
\]</span></p>
<p>Likewise with rotation, we can construct a <em>rotation matrix</em> <span class="math">\(\RR_{\theta}\)</span> to rotate a point <span class="math">\(\pp\)</span> by <span class="math">\(\theta\)</span> radians <em>about the origin</em>:</p>
<p><span class="math">\[
\pp = \vxy{1}{0}
\hskip{0.5in}
\pp&#39; = \RR_{\pi}\pp = \vxy{-1}{0}
\]</span></p>
<p><img src="/generated-images/tikz-527fe6a824a2f0e7f2ac0cc5c439eeec1caeadb2.png" width="366" height="437" class="eq-right"></p>
<p>If we want to rotate an object <em>about a specific point</em> <span class="math">\(\qq = \sm{a \\ b}\)</span>, we can express this as a product of matrices <span class="math">\(\TT_{a,b}\)</span> and <span class="math">\(\RR_{\theta}\)</span>:</p>
<p><span class="math">\[
\pp&#39; = \TT_{a,b}\RR_{\theta}\TT_{a,b}^{-1}\pp
\]</span></p>
<p>First we use <span class="math">\(\TT_{a,b}^{-1}\)</span> to translate everything so that the point expressed by <span class="math">\((a,b)\)</span> is the origin, then we rotate as desired by applying <span class="math">\(\RR_{\theta}\)</span>, and translate everything back to its original location by applying <span class="math">\(\TT_{a,b}\)</span>. To do this we need <span class="math">\(\TT_{a,b}\)</span> to be invertible. We might also wish to modularize this transformation as a new matrix <span class="math">\(\A=\TT\RR\TT^{-1}\)</span> and include it in other transformations so we need all of the matrices involved to be invertible.</p>
<p>Here are the inverses of <span class="math">\(\TT_{a,b}\)</span> and <span class="math">\(\RR_{\theta}\)</span>:</p>
<p><span class="math">\[
\begin{align*}
\TT_{a,b}^{-1} &amp;= \TT_{-a,-b} \\
\RR_{\theta}^{-1} &amp;= \RR_{-\theta}
\end{align*}
\]</span></p>
<p>Some properties of invertible matrices are:</p>
<ul>
<li><p>An invertible matrix has only one solution to <span class="math">\(\A\xx=0\)</span>, and that solution is the zero vector. This is because the matrix has <em>independent column vectors</em>: no two column vectors is a combination of any other. If the columns are <em>not</em> independent, then there is some way to combine some of the columns to yield the others. If that is the case, then that combination yields a nonzero solution to <span class="math">\(\A\xx=0\)</span>.</p></li>
<li><p>Invertible matrices will have a full set of pivots after elimination; non-invertible matrices will have a zero pivot at some point during elimination leading to elimination failure. A missing pivot means we have some unknown with a coefficient of zero which leads to an infinite number of solutions or no solutions for that particular equation.</p></li>
</ul>
<h2 id="afterword">Afterword</h2>
<p>In this post we've seen how we can think of matrix inverses as &quot;undoing&quot; a matrix multiplication and we looked at a few properties of inverse matrices. There are many more; for a full list, see <a href="http://en.wikipedia.org/wiki/Invertible_matrix">the full Wikipedia article on the subject</a>. For more information on linear transformations such as those indicated by <span class="math">\(\TT_{a,b}\)</span> and <span class="math">\(\RR_{\theta}\)</span>, see <a href="http://en.wikipedia.org/wiki/Transformation_matrix">the Wikipedia article on transformation matrices</a>. Next time we'll look at Gauss-Jordan elimination, a modified elimination process that finds the inverse <span class="math">\(\A^{-1}\)</span> of <span class="math">\(\A\)</span> if it exists.</p>
</div>
<div id="disqus_thread"></div>
<script type="text/javascript">
  /**
    * var disqus_identifier; [Optional but recommended: Define a unique identifier (e.g. post id or slug) for this thread] 
    */
  var disqus_identifier = "linear-algebra-6";
  (function() {
   var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
   dsq.src = 'http://derivativeworks.disqus.com/embed.js';
   (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>
<noscript>
  Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript=derivativeworks">comments.</a>
</noscript>
      <div id="footer">
        Copyright &copy; 2010-2013 Jonathan Daugherty
      </div>
    </div>
  </body>
</html>